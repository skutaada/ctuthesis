 @ARTICLE{cite:1,  author={Vrba, Matouš and Heřt, Daniel and Saska, Martin},  journal={IEEE Robotics and Automation Letters},   title={Onboard Marker-Less Detection and Localization of Non-Cooperating Drones for Their Safe Interception by an Autonomous Aerial System},   year={2019},  volume={4},  number={4},  pages={3402-3409},  doi={10.1109/LRA.2019.2927130}}
 
 @article{cite:2,
 	author = {Krajn\'{\i}k, Tom\'{a}\v{s} and Nitsche, Mat\'{\i}as and Faigl, Jan and Vanundefinedk, Petr and Saska, Martin and P\v{r}eu\v{c}il, Libor and Duckett, Tom and Mejail, Marta},
 	title = {A Practical Multirobot Localization System},
 	year = {2014},
 	issue_date = {December  2014},
 	publisher = {Kluwer Academic Publishers},
 	address = {USA},
 	volume = {76},
 	number = {3–4},
 	issn = {0921-0296},
 	url = {https://doi.org/10.1007/s10846-014-0041-x},
 	doi = {10.1007/s10846-014-0041-x},
 	abstract = {We present a fast and precise vision-based software intended for multiple robot localization. The core component of the software is a novel and efficient algorithm for black and white pattern detection. The method is robust to variable lighting conditions, achieves sub-pixel precision and its computational complexity is independent of the processed image size. With off-the-shelf computational equipment and low-cost cameras, the core algorithm is able to process hundreds of images per second while tracking hundreds of objects with millimeter precision. In addition, we present the method's mathematical model, which allows to estimate the expected localization precision, area of coverage, and processing speed from the camera's intrinsic parameters and hardware's processing capacity. The correctness of the presented model and performance of the algorithm in real-world conditions is verified in several experiments. Apart from the method description, we also make its source code public at http://purl.org/robotics/whycon ; so, it can be used as an enabling technology for various mobile robotic problems.},
 	journal = {J. Intell. Robotics Syst.},
 	month = {dec},
 	pages = {539–562},
 	numpages = {24},
 	keywords = {Mobile robotics, Computer vision, Localization, Swarm robotics}
 }

@article{cite:3,
	title = {Swarms of Unmanned Aerial Vehicles — A Survey},
	journal = {Journal of Industrial Information Integration},
	volume = {16},
	pages = {100106},
	year = {2019},
	issn = {2452-414X},
	doi = {https://doi.org/10.1016/j.jii.2019.100106},
	url = {https://www.sciencedirect.com/science/article/pii/S2452414X18300086},
	author = {Anam Tahir and Jari Böling and Mohammad-Hashem Haghbayan and Hannu T. Toivonen and Juha Plosila},
	keywords = {Swarm of drones, Swarm of Unmanned Aerial Vehicles},
	abstract = {The unmanned aerial vehicles or drones come in a great diversity depending upon the basic frameworks with their particular specifications. The purpose of this study is to analyse the core characteristics of the swarming drones and measure the public awareness levels with respect to these swarms. To achieve these goals, the functionality, problems, and importance of drones are highlighted. The results of an experimental survey from a bunch of academic population are also presented, which demonstrate that the swarms of drones are fundamental future agenda and will be adopted with the passage of time.}
}

@INPROCEEDINGS{cite:4,  author={Lee, Seoungjun and Har, Dongsoo and Kum, Dongsuk},  booktitle={2016 3rd Asia-Pacific World Congress on Computer Science and Engineering (APWC on CSE)},   title={Drone-Assisted Disaster Management: Finding Victims via Infrared Camera and Lidar Sensor Fusion},   year={2016},  volume={},  number={},  pages={84-89},  doi={10.1109/APWC-on-CSE.2016.025}}

@article{cite:5,
	title={An Image Inpainting Technique Based on the Fast Marching Method},
	author={Alexandru Cristian Telea},
	journal={Journal of Graphics Tools},
	year={2004},
	volume={9},
	pages={23 - 34}
}

@misc{ma2018sparsetodense,
	title={Sparse-to-Dense: Depth Prediction from Sparse Depth Samples and a Single Image}, 
	author={Fangchang Ma and Sertac Karaman},
	year={2018},
	eprint={1709.07492},
	archivePrefix={arXiv},
	primaryClass={cs.RO}
}

@misc{redmon2016look,
	title={You Only Look Once: Unified, Real-Time Object Detection}, 
	author={Joseph Redmon and Santosh Divvala and Ross Girshick and Ali Farhadi},
	year={2016},
	eprint={1506.02640},
	archivePrefix={arXiv},
	primaryClass={cs.CV}
}

@misc{redmon2018yolov3,
	title={YOLOv3: An Incremental Improvement}, 
	author={Joseph Redmon and Ali Farhadi},
	year={2018},
	eprint={1804.02767},
	archivePrefix={arXiv},
	primaryClass={cs.CV}
}

@misc{kathuria_2018, title={What's new in YOLO v3?}, url={https://towardsdatascience.com/yolo-v3-object-detection-53fb7d3bfe6b}, journal={Medium}, publisher={Towards Data Science}, author={Kathuria, Ayoosh}, year={2018}, month={Apr}}

@misc{opencv, title={Camera Calibration and 3D Reconstruction}, url={https://docs.opencv.org/4.x/d9/d0c/group__calib3d.html}, journal={OpenCV}}

